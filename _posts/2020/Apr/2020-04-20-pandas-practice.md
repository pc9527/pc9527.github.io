---
title: 还在玩Excel？Pandas才是2020年分析数据的终极利器
---
# 还在玩Excel？Pandas才是2020年分析数据的终极利器

作为一个职业生涯中正经练过Excel的社畜，曾经说“Excel是微软最牛逼的软件”——这话在今天更加正确了...

数据统计分析，无论是何种需求，都可以通过透视表、函数或写VB Script来完成，除了当年机器性能不行超过10万行数据就开始挪不动鼠标了，没什么缺点。

但在现在老革命要解决新问题：大量数据的统计和分析。倒不是说处理不了会死机，i7 8700 + 32G内存已经足以平趟千万行以内的任何数据——而是Excel的设计哲学和使用场景——终究是面向可视化的，工作对象和思考模式以及最终展示结果都是基于眼前这些格子。

然而数据分析和统计需要更抽象一层的思考，不说建模那么学院派，起码对逻辑要有个判断，然后从数据里寻找支持自己的各种展示——这时，编程作为思考这一古老技艺的延伸，就派上用场了。

Pandas最早是用于金融数据分析的工具，开源以后更是依托Python生态迅猛发展，因为基于代码，所以给使用者更广阔的想象空间（没Excel好上手就直说！）

比如基础数据结构Series和DataFrame，代表一维和二维数据，可以任意拆分组合，想象力才是你的极限——用惯了Excel和csv的我好半天才适应——路径依赖是魔鬼。

本文不是技术介绍文，只说一下做数据分析的日常形态：

打开Python console，装载数据，想起什么要验证的，随时敲个
```
df["2018"]["level"].value_counts()
```

做个按值计数，或者
```
df.groupby(["level", "kpi"]).head(10)
```
看看都有那些可统计对象，掌握了这些用法之后，“随时通过数据来支持自己的想法”就成了触手可及的操作，可以每天做100次。

一句话总结：Excel基于见识，Pandas纯靠想法。

单点效率的量级式提升，给日常工作流其他部分带来的效益不一定等同，然而，这已经是升级过后的你了。
